# ğŸ– Detector de Lengua de SeÃ±as

Este proyecto es un **detector de lengua de seÃ±as** que combina visiÃ³n por computadora y reconocimiento de voz para facilitar la comunicaciÃ³n entre personas con discapacidad auditiva y oyentes.

---

## ğŸ“š DescripciÃ³n

El programa tiene **dos marcos principales (frames)**, representando dos caras de la moneda:

âœ… **Para la persona con discapacidad auditiva (persona especial):**  
Utilizando la webcam, el sistema reconoce la seÃ±a que realiza y traduce a quÃ© letra o expresiÃ³n corresponde.

âœ… **Para la persona oyente (persona normal):**  
Mediante reconocimiento de voz, el sistema detecta lo que la persona dice y muestra en pantalla una imagen con la seÃ±a correspondiente, permitiendo que la persona especial comprenda el mensaje.

---

## ğŸ¯ Objetivo

Este proyecto se presentarÃ¡ el **10 de mayo** en la **Feria de MatemÃ¡ticas** de la **Universidad Nacional de IngenierÃ­a (UNI), Centro Regional Juigalpa**.  
El propÃ³sito es demostrar que las matemÃ¡ticas son fundamentales para el desarrollo de la inteligencia artificial, y que estos conocimientos pueden aplicarse en la vida real para resolver problemas complejos y generar un impacto positivo en la sociedad.

---

## âš™ï¸ CÃ³mo funciona

El proyecto se desarrolla en **varias etapas** mediante diferentes scripts:

1ï¸âƒ£ **RecolecciÃ³n de imÃ¡genes**  
Archivo: `collect_imgs.py`  
ğŸ‘‰ Toma 100 fotos por cada letra del abecedario o expresiÃ³n, usando la cÃ¡mara.

2ï¸âƒ£ **CreaciÃ³n del dataset**  
Archivo: `create_dataset.py`  
ğŸ‘‰ A partir de las imÃ¡genes recolectadas, crea un dataset que servirÃ¡ como base de informaciÃ³n para entrenar el modelo.

3ï¸âƒ£ **Entrenamiento del modelo**  
Archivo: `train_inference.py`  
ğŸ‘‰ Usa los archivos `.pickle` generados en la etapa anterior para entrenar el modelo y generar el archivo final del modelo.

4ï¸âƒ£ **ClasificaciÃ³n en tiempo real**  
Archivo: `inference_classifier.py`  
ğŸ‘‰ Usa el modelo entrenado para reconocer el lenguaje de seÃ±as captado por la webcam.

5ï¸âƒ£ **Reconocimiento de voz**  
Archivo: `speech_to_sign.py`  
ğŸ‘‰ Reconoce frases habladas y muestra en pantalla la imagen de la seÃ±a correspondiente.

6ï¸âƒ£ **IntegraciÃ³n de ambos mundos**  
Archivo: `unified_frames.py`  
ğŸ‘‰ Unifica los dos sistemas en dos marcos verticales, permitiendo que la persona normal y la persona especial puedan comunicarse de forma efectiva y fluida.

---

## ğŸ›  TecnologÃ­as utilizadas

- [MediaPipe](https://mediapipe.dev/)  
- [OpenCV](https://opencv.org/)  
- `sounddevice==0.5.1`  
- `SpeechRecognition==3.14.2`  
- `scikit-learn`

---

## ğŸš€ Futuro

Se planea integrar este sistema en una plataforma web accesible para cualquier persona, ampliando su alcance y generando aÃºn mÃ¡s impacto social.

---

## ğŸ“¸ Ejemplo visual

![Ejemplo del sistema en uso](README_Ejemplo.png)

---

## ğŸ’¡ CrÃ©ditos

Proyecto desarrollado por [NicaDevs](https://github.com/NicaDevs) para la Feria de MatemÃ¡ticas 2025.  
Contribuciones de: Elmer Urbina y Holman Rugama.

